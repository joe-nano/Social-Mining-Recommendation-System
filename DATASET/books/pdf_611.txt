articles assemblage pdfAnalyse globale du flux optique pour la dÃ©tection dâ€™Ã©vÃ¨nements dans une scÃ¨ne de foule Yassine Benabbas Nacim Ihaddadene Thierry Urruty Chabane Djeraba Laboratoire dâ€™Informatique Fondamentale de Lille LIFL UMR 8022 USTL CNRS UniversitÃ© des Sciences et Technologies de Lille 1 59650 Villeneuve dâ€™Ascq France {yassine benabbas nacim ihaddadene thierry urruty chabane djeraba} lifl fr RÃ©sumÃ© Les systÃ¨mes de vidÃ©o surveillance sont de plus en plus autonomes dans la dÃ©tection des Ã©vÃ©nements anormaux Cet article prÃ©sente une mÃ©thode de dÃ©tection des flux majeurs et des Ã©vÃ¨nements qui surviennent dans une scÃ¨ne de foule Ces dÃ©tections sont effectuÃ©es en utilisant un modÃ¨le directionnel construit Ã  partir dâ€™un mÃ©lange de lois de von Mises appliquÃ© Ã  lâ€™orientation des vecteurs de mouvement Les flux majeurs sont alors calculÃ©s en rÃ©cupÃ©rant les orienta tions les plus importantes des mÃ©langes Divers Ã©vÃ¨nements se produisant dans une foule sont aussi dÃ©tectÃ©s en utilisant en plus du modÃ¨le dâ€™orientation un modÃ¨le probabiliste de magnitude des vecteurs de mouvement Les rÃ©sultats de lâ€™expÃ©rimentation sur un Ã©chantillon de vidÃ©os dâ€™Ã©vÃ©nements sont prÃ©sentÃ©s 1 Introduction La sÃ©curitÃ© des personnes et des biens est un des problÃ¨mes majeurs dans les zones pu bliques telles que les aÃ©roports les stations de mÃ©tro les centres commerciaux ou les places publiques Le traitement automatique des vidÃ©os provenant de camÃ©ras de surveillance est de plus en plus utilisÃ© pour prÃ©senter une information pertinente aux opÃ©rateurs qui doivent agir dans les situations critiques dangereuses ou inhabituelles Ces derniÃ¨res annÃ©es ont vu lâ€™in tÃ©gration dans les systÃ¨mes de vidÃ©o surveillance dâ€™algorithmes de dÃ©tection de mouvements dâ€™Ã©vÃ©nements de bagages abandonnÃ©s ou de suivi de personnes Cependant vu la complexitÃ© du problÃ¨me peu de systÃ¨mes se sont penchÃ©s sur les situations impliquant des foules de per sonnes Lâ€™analyse des flux de personnes consiste Ã  dÃ©tecter les tendances de mouvement dans les zones surveillÃ©es Elle devient nÃ©cessaire lorsque le suivi dâ€™objets individuels Ã©choue ce qui est souvent le cas dans une scÃ¨ne de foule Cette analyse est effectuÃ©e en traitant lâ€™information de mouvement Ã  travers des images successives La dÃ©tection dâ€™Ã©vÃ¨nements est dÃ©finie comme Ã©tant la dÃ©tection des situations qui attirent lâ€™attention dâ€™une personne Shyu et al 2008 Câ€™est un domaine vaste du Ã  lâ€™immense quantitÃ© dâ€™Ã©vÃ¨nements possibles En plus la dÃ©finition dâ€™un Ã©vÃ¨nement change dâ€™une personne Ã  une autre et dÃ©pend fortement du contexte Beaucoup dâ€™efforts ont Ã©tÃ© fournis pour la dÃ©tection dâ€™Ã©vÃ¨nements atomiques qui reprÃ©sentent un Ã©lÃ©ment de base pour la dÃ©tection de situations plus complexes RNTI E 19 339 DÃ©tection dâ€™Ã©vÃ¨nements dans une scÃ¨ne de foule Dans cet article nous introduisons un modÃ¨le probabiliste pour reprÃ©senter une scÃ¨ne Ce modÃ¨le gÃ¨re efficacement la complexitÃ© des scÃ©narios et lâ€™imprÃ©visibilitÃ© des comportements Notre approche a Ã©tÃ© appliquÃ©e sur une sÃ©lection dâ€™Ã©vÃ¨nements et expÃ©rimentÃ©e sur lâ€™Ã©chan tillon de vidÃ©os du workshop PETSâ€™2009 1 Cet article est organisÃ© comme suit Tout dâ€™abord La section 2 prÃ©sente quelques travaux antÃ©rieurs traitant du problÃ¨me de lâ€™analyse de foule La section 3 dÃ©taille la modÃ©lisation de la scÃ¨ne La section 4 dÃ©crit la mÃ©thodologie adoptÃ©e pour lâ€™extraction des flux dâ€™une scÃ¨ne et la dÃ©tection dâ€™Ã©vÃ¨nements dans une scÃ¨ne de foule Les rÃ©sultats de lâ€™expÃ©rimentation sur lâ€™Ã©chantillon de vidÃ©os PETSâ€™2009 sont prÃ©sentÃ©s dans la section 5 La section 6 conclue cet article et dÃ©crit les travaux futurs potentiels 2 Travaux antÃ©rieurs Les approches traditionnelles pour lâ€™analyse des Ã©vÃ©nements dans une sÃ©quence vidÃ©o sont composÃ©es des Ã©tapes suivantes Hu et al 2008 la dÃ©tection de tous les sujets mobiles prÃ©sents dans la scÃ¨ne Ã  un instant ğ‘¡ le suivi des sujets dÃ©tectÃ©s dans les instants suivants et lâ€™analyse des allures et des trajectoires des sujets pour la dÃ©tection dâ€™Ã©vÃ¨nements ou dâ€™activitÃ©s Cependant cette approche a beaucoup de faiblesses quand elle est appliquÃ©e Ã  des scÃ¨nes ou scÃ©narios complexes impliquant une large foule ParallÃ¨lement Les approches globales traitent lâ€™intÃ©gralitÃ© de la scÃ¨ne sans se focaliser sur les individus sÃ©parÃ©ment Elles sont classÃ©es en deux catÃ©gories la premiÃ¨re consiste Ã  estimer la densitÃ© de la foule et la seconde Ã  extraire des motifs de mouvement ou dÃ©tecter des Ã©vÃ¨nements dans une scÃ¨ne de foule Dans la premiÃ¨re catÃ©gorie on distingue les mÃ©thodes basÃ©es sur lâ€™extraction des textures et sur lâ€™analyse des proportions des surfaces en mouvement Marana et al 1997 Rahmalan et al 2006 Lin et al 2001 Ma et al 2004 Ces mÃ©thodes fournissent une analyse statique intÃ©ressante pour la surveillance des foules mais ne dÃ©tectent pas les Ã©vÃ¨nements anormaux Il existe aussi quelques techniques basÃ©es sur le flux optique Boghossian et Velastin 1999 Davies et al 1995 qui dÃ©tectent des foules stationnaires ou suivent des individus en utilisant plusieurs camÃ©ras Cupillard et al 2004 Dans la deuxiÃ¨me catÃ©gorie le but est de dÃ©tecter les Ã©vÃ¨nements anormaux dans une foule en se basant sur les motifs de mouvement Le principe dâ€™extraction des motifs de mouvement est de modÃ©liser les comportements les plus frÃ©quents et de considÃ©rer les Ã©vÃ¨nements anor maux comme des cas aberrants La dÃ©viation des comportements typiques est ainsi utilisÃ©e pour caractÃ©riser lâ€™anormalitÃ© Plusieurs techniques ont Ã©tÃ© proposÃ©es pour cette catÃ©gorie Andrade et al 2006a b com binent les modÃ¨les de Markov cachÃ©s avec lâ€™analyse en composantes principales des vecteurs du flux optique pour dÃ©tecter des scÃ©narios dâ€™urgences Cependant les expÃ©rimentations ont Ã©tÃ© portÃ©es sur des donnÃ©es simulÃ©es Ali et Shah 2007 utilisent la dynamique des parti cules Lagrangiennes pour dÃ©tecter les instabilitÃ©s du flux Cette mÃ©thode est efficace pour la segmentation des grandes densitÃ©s de foules marathons Ã©vÃ¨nements politiques et religieux etc Ihaddadene et Djeraba 2008 detectent les situations dâ€™Ã©croulement en se basant sur une mesure qui dÃ©crit le degrÃ© dâ€™organisation ou de dÃ©sordre des vecturs de flux optique Cette approche fonctionne sur des zones unidirectionnelles e g escalators Mehran et al 2009 1 cvg rdg ac uk PETS2009 RNTI E 19 340 Y BENABBAS et al utilisent le flux optique pure pour dÃ©tecter les comportements anormaux dans la foule en utili sant un modÃ¨le de force sociale Wright et Pless 2005 dÃ©terminent les motifs de mouvement persistants avec une distribution jointe globale des distributions indÃ©pendantes des gradients de luminositÃ© locaux Cette variable alÃ©atoire est modÃ©lisÃ©e avec un mÃ©lange Gaussien Cette approche assume que tous les mouvements sur une image sont cohÃ©rents e g voitures cette hypothÃ¨se est violÃ©e quand les piÃ©tons se dÃ©placent indÃ©pendamment Lâ€™approche proposÃ©e contribue Ã  la dÃ©tection des orientations majeures dans une scÃ¨ne complexe dÃ» au fait quâ€™elle construit en ligne un modÃ¨le probabiliste sur lâ€™orientation du mouvement sur la scÃ¨ne qui opÃ¨re en temps rÃ©el Elle contribue aussi dans la dÃ©tection dâ€™Ã©vÃ¨ nements dans la foule en suivant des groupes de personne au lieu de suivre chaque personne individuellement ce qui facilite la dÃ©tection dâ€™Ã©vÃ¨nements se produisant sur des foules 3 DÃ©tection et suivi de groupes Lâ€™approche proposÃ©e est composÃ©e de plusieurs Ã©tapes Figure 1 La premiÃ¨re consiste Ã  extraire un ensemble de points dâ€™intÃ©rÃªt dans lâ€™image courante Ces points sont par la suite traquÃ©s dans lâ€™image suivante en utilisant des techniques de calcul du flux optique Les points statiques sont supprimÃ©s pour se focaliser sur les sujets en mouvement La scÃ¨ne est divisÃ©e en blocs et chaque vecteur de mouvement est attachÃ© au bloc correspondant FIG 1 â€“ Ã‰tapes de lâ€™algorithme Lâ€™Ã©tape de classification des blocs regroupe les blocs voisins ayant une orientation et une vitesse similaires Enfin les Ã©vÃ¨nements sont dÃ©tectÃ©s en exploitant les informations du suivi de groupes le modÃ¨le de magnitudes et le modÃ¨le directionnel RNTI E 19 341 DÃ©tection dâ€™Ã©vÃ¨nements dans une scÃ¨ne de foule 3 1 DÃ©tection et suivi de points dâ€™intÃ©rÃªt Ces Ã©tapes permettent dâ€™extraire un ensemble de points dâ€™intÃ©rÃªt Ã  partir dâ€™une image de la sÃ©quence vidÃ©o en utilisant la mÃ©thode dÃ©crite dans Harris et Stephens 1988 Nous consi dÃ©rons que dans les scÃ¨nes de vidÃ©o surveillance les positions des camÃ©ras et les conditions de luminositÃ© permettent dâ€™extraire un nombre consÃ©quent de points dâ€™intÃ©rÃªt Tous les points dâ€™intÃ©rÃªt de lâ€™image sont traquÃ©s dans lâ€™image suivante en utilisant lâ€™algorithme de calcul de flux optique Lucas et Kanade 1981 Shi et Tomasi 1994 Le rÃ©sultat de cette opÃ©ration Ã  lâ€™instant ğ‘¡ est un ensemble ğ‘‰ğ‘¡ de vecteurs Ã  4 dimensions ğ‘‰ğ‘¡ = {ğ‘‰1 ğ‘‰ğ‘ âˆ£ğ‘‰ğ‘– = ğ‘‹ğ‘– ğ‘Œğ‘– ğ´ğ‘– ğ‘€ğ‘– } oÃ¹ ğ‘‹ğ‘– et ğ‘Œğ‘– sont les coordonnÃ©es du point ğ‘– par rapport au repÃ¨re de lâ€™image ğ¼ğ‘¡ ğ´ğ‘– est lâ€™angle ou lâ€™orientation de mouvement du point ğ‘– ğ‘€ğ‘– est la magnitude de mouvement du point ğ‘– elle correspond Ã  la distance entre la position du point ğ‘– dans lâ€™image ğ¼ğ‘¡ et sa nouvelle position dans lâ€™image ğ¼ğ‘¡+1 Cette Ã©tape permet dâ€™enlever les points dâ€™intÃ©rÃªts statiques qui ont une magnitude de mouvement infÃ©rieure Ã  une magnitude minimale Finalement lâ€™image est divisÃ©e en blocs de ğµğ‘¥ lignes et ğµğ‘¦ colonnes Chaque vecteur de mouvement est affectÃ© au bloc adÃ©quat selon son origine Nous considÃ©rons des blocs de dimension 16 Ã— 16 pixels afin dâ€™obtenir un bon Ã©quilibre entre le temps de traitement et la qualitÃ© les rÃ©sultats 3 2 Le modÃ¨le de magnitude et le modÃ¨le de direction Dans cette Ã©tape on calcule la direction du flux optique dans chaque bloc Ces directions sont les entrÃ©s de la loi de probabilitÃ© du bloc La loi locale pour un bloc ğµğ‘¥ ğ‘¦ est construite en utilisant un mÃ©lange de lois de von Mises aussi appelÃ©e loi normale circulaire La probabilitÃ© dâ€™un variable angulaire ğœƒ est donnÃ©e par ğ‘ƒğ‘¥ ğ‘¦ ğœƒ = ğ¾âˆ‘ ğ‘–=1 ğœ”ğ‘– ğ‘¥ ğ‘¦ â‹… ğ‘‰ ğœƒ ğœ‡ğ‘– ğ‘¥ ğ‘¦ ğ‘šğ‘– ğ‘¥ ğ‘¦ 1 oÃ¹ğ¾ est le nombre de distributions Il reprÃ©sente le nombre maximum dâ€™orientations prin cipales considÃ©rÃ© ğœ”ğ‘– ğ‘¥ ğ‘¦ ğœ‡ğ‘– ğ‘¥ ğ‘¦ et ğ‘šğ‘– ğ‘¥ ğ‘¦ sont respectivement le poids la direction modale et le paramÃ¨tre de concentration de la ğ‘–ğ‘šğ‘’ loi du bloc ğµğ‘¥ ğ‘¦ ğ‘‰ ğœƒ ğœ‡ ğ‘š est la loi de von Mises de direction modale ğœ‡ et paramÃ¨tre de concentration ğ‘š Elle se caractÃ©rise par sa densitÃ© sur [0 2ğœ‹[ ğ‘‰ ğœƒ ğœ‡ ğ‘š = 1 2ğœ‹ğ¼0 ğ‘š exp [ğ‘š cos ğœƒ âˆ’ ğœ‡ ] 2 oÃ¹ ğ¼0 ğ‘š est la fonction de Bessel modifiÃ©e de premiÃ¨re espÃ¨ce et dâ€™ordre 0 dÃ©finie par ğ¼0 ğ‘š = âˆâˆ‘ ğ‘Ÿ=0 1 ğ‘Ÿ 2 1 2 ğ‘š 2ğ‘Ÿ 3 La figure 2 montre une reprÃ©sentation de la fonction densitÃ© dâ€™un bloc on y distingue les deux tendances dâ€™orientation gauche et droite RNTI E 19 342 Y BENABBAS et al FIG 2 â€“ ReprÃ©sentation dâ€™un mÃ©lange de 2 lois de von Mises Dans les espaces publiques les personnes se dirigent gÃ©nÃ©ralement dans des directions diffÃ©rentes Ainsi certaines zones ont des motifs de mouvement qui contiennent 2 orientations principales ou plus Par exemple il y a 4 orientations principales dans un passage piÃ©ton 2 orientations opposÃ©es pour les piÃ©tons et deux autres pour les voitures Il serait intÃ©ressant de savoir qui des piÃ©tons ou des voitures emprunte ce passage Ceci peut Ãªtre fait en utilisant le modÃ¨le directionnel En effet le modÃ¨le de mÃ©lange de chaque bloc peut contenir jusquâ€™Ã  4 orientations principales Le poids nous informe de lâ€™importance dâ€™une orientation FIG 3 â€“ ReprÃ©sentation des directions dominantes par bloc Pour chaque image les paramÃ¨tres du mÃ©lange sont mis Ã  jour en utilisant un algorithme en ligne dâ€™approximation E M Kaewtrakulpong et Bowden 2001 qui est Ã  lâ€™origine utilisÃ© pour estimer un mÃ©lange Gaussien Lâ€™algorithme a Ã©tÃ© adaptÃ© pour traiter des observations circulaires au lieu dâ€™observations linÃ©aires Lâ€™inverse de la variance ğœ de la loi normale est considÃ©rÃ© comme Ã©tant le paramÃ¨tre de concentration ğ‘š = 1 ğœ2 La figure 3 montre la reprÃ© sentation la loi de probabilitÃ© pour 2 blocs Les tendances de direction peuvent Ãªtre perÃ§ues RNTI E 19 343 DÃ©tection dâ€™Ã©vÃ¨nements dans une scÃ¨ne de foule Dans ce papier on choisitğ¾ = 4 afin de reprÃ©senter les 4 points cardinaux Le modÃ¨le de magnitude est un mÃ©lange Gaussien unidimensionnel sur la magnitude moyenne du mouvement entre deux images Elle est dÃ©finie comme suit ğ‘ƒ ğ‘¥ = 4âˆ‘ ğ‘˜=1 ğœ”ğ‘˜ 1 ğœğ‘˜ âˆš 2ğœ‹ ğ‘’ğ‘¥ğ‘ âˆ’ ğ‘¥âˆ’ ğœ‡ğ‘˜ 2 2ğœ2ğ‘˜ 4 oÃ¹ ğœ”ğ‘˜ ğœ‡ğ‘˜ et ğœğ‘˜ sont respectivement le poids la moyenne et la variance de la ğ‘˜ğ‘šğ‘’ Gaussienne Les paramÃ¨tres du mÃ©lange sont appris avec un algorithme dâ€™apprentissage en ligne sur les donnÃ©es vidÃ©o â€™S0 normal flowâ€™ appartenant Ã  la base de vidÃ©os de PETSâ€™2009 Ces sÃ©quences contiennent des personne qui marchent a Image initiale b Tendences de direction FIG 4 â€“ ReprÃ©sentation des flux multiples dâ€™une image 3 3 Regroupement des blocs Lâ€™objectif de cette opÃ©ration est de rassembler les blocs dâ€™image entre eux pour obtenir des groupes reprÃ©sentant des entitÃ©s ayant des directions similaires Ces groupes peuvent re prÃ©senter une ou plusieurs personnes Les critÃ¨res dâ€™affectation dâ€™un bloc Ã  un groupe sont la direction et la vitesse Ainsi les blocs voisins ayant une magnitude moyenne et une orientation principale similaires seront rattachÃ©s au mÃªme groupe Chaque bloc ğµğ‘¥ ğ‘¦ est dÃ©fini par sa position ğ‘ƒğ‘¥ ğ‘¦ = ğ‘¥ ğ‘¦ ğ‘¥ = 1 ğµğ‘¥ ğ‘¦ = 1 ğµğ‘¦ et orientation Î©ğ‘¥ ğ‘¦ = ğœ‡0 ğ‘¥ ğ‘¦ voir section 3 2 La figure 5 illustre le rÃ©sultat de cette Ã©tape 3 4 Suivi de groupes Le suivi permet de retracer la trajectoire de la personne ou du groupe de personnes depuis son apparition dans le champ de la camÃ©ra jusquâ€™Ã  sa disparition Cette opÃ©ration est effectuÃ©e en mettant en correspondance les barycentres des groupes dans lâ€™image ğ‘“ avec les barycentres de lâ€™image ğ‘“+1 Chaque image ğ‘“ est dÃ©finie par ses groupes {ğ¶1 ğ‘“ ğ¶2 ğ‘“ ğ¶ğ‘›ğ‘“ ğ‘“} oÃ¹ ğ‘›ğ‘“ est le nombre de groupes dÃ©tectÃ©s dans lâ€™image ğ‘“ Chaque groupeğ¶ğ‘– ğ‘“ est dÃ©crit par son barycentre RNTI E 19 344 Y BENABBAS et al a Segmentation des blocs b Image dâ€™origine avec les groupes rÃ©sualtants FIG 5 â€“ Regroupement des blocs ğ‘‚ğ‘– ğ‘“ et son orientation moyenne ğ‘‹ğ‘– ğ‘“ Le groupe ğ¶ğ‘š ğ‘“+1 correspond au groupe ğ¶ğ‘– ğ‘“ si son barycentre est le plus proche de ğ¶ğ‘– ğ‘“ sans dÃ©passer une distance minimale En dâ€™autres termes elle doit satisfaire ces deux conditions â§ï£´â¨ï£´â© ğ‘š = argmin ğ‘— ğ· ğ‘‚ğ‘– ğ‘“ ğ‘‚ğ‘— ğ‘“+1 ğ‘’ğ‘¡ ğ· ğ‘‚ğ‘– ğ‘“ ğ‘‚ğ‘š ğ‘“+1 < ğœ 5 oÃ¹ ğœ est la distance minimale entre deux groupes on a choisi ğœ = 5 Si aucune correspondance nâ€™a Ã©tÃ© trouvÃ©e aucun groupe ğ¶ğ‘š ğ‘“+1 ne satisfait les deux conditions alors le groupe ğ¶ğ‘– ğ‘“ a disparu et nâ€™est plus suivi dans les prochaines images 4 DÃ©tection dâ€™Ã©vÃ¨nements dans une scÃ¨ne de foule Dans cette section nous dÃ©crivons les traitements nÃ©cessaires pour dÃ©tecter certains Ã©vÃ©ne ments liÃ©s aux foules de personnes Les scÃ©narios retenus font partie des Ã©vÃ©nements dÃ©crits dans le workshop PETSâ€™2009 â€“ Ã‰vÃ¨nements liÃ©s Ã  la vitesse de mouvement il sâ€™agit de dÃ©tecter si les personnes qui forment la foule marchent ou courent Ces Ã©vÃ©nements peuvent Ãªtre dÃ©tectÃ©s en exploi tant la magnitude des vecteurs de flux optique Ã  travers les images â€“ Le rassemblement cet Ã©vÃ©nement se produit quand deux ou plusieurs groupes se re joignent pour former un seul groupe â€“ La division cet Ã©vÃ©nement se produit lorsque les personnes qui forment un groupe se sÃ©parent pour des raisons telles que la dispersion ou lâ€™Ã©vacuation Les Ã©vÃ¨nements de la premiÃ¨re catÃ©gorie sont dÃ©tectÃ©s en comparant la magnitude moyenne du flux optique de chaque image au modÃ¨le de magnitude de la scÃ¨ne obtenu par apprentissage Les Ã©vÃ¨nements de la deuxiÃ¨me et troisiÃ¨me catÃ©gorie sont dÃ©tectÃ©s en analysant la position et la vitesse des groupes Un explication plus dÃ©taillÃ©e sera donnÃ©e dans ce qui suit RNTI E 19 345 DÃ©tection dâ€™Ã©vÃ¨nements dans une scÃ¨ne de foule 4 1 Ã‰vÃ¨nements relatifs Ã  lâ€™allure Comme dÃ©crite prÃ©cÃ©demment lâ€™idÃ©e principale est de comparer la magnitude moyenne des vecteurs de mouvement de chaque image au modÃ¨le de magnitude de la scÃ¨ne pour ob tenir les probabilitÃ© ğ‘ƒğ‘šğ‘ğ‘Ÿğ‘â„ ğ‘ƒğ‘ğ‘œğ‘¢ğ‘Ÿ des Ã©vÃ¨nements marcher et courir respectivement Dans cet article puisque les vecteurs de mouvement sont considÃ©rÃ©s pour la dÃ©tection bas niveau et ğ‘ƒğ‘ğ‘œğ‘¢ğ‘Ÿ = 1 âˆ’ ğ‘ƒğ‘šğ‘ğ‘Ÿğ‘â„ Le calcul de ğ‘ƒğ‘ğ‘œğ‘¢ğ‘Ÿ permettra donc de dÃ©duire lâ€™occurrence de lâ€™Ã©vÃ¨ nement courir et marcher Sous lâ€™hypothÃ¨se quâ€™il y a plus de probabilitÃ© pour un groupe de rester dans son Ã©tat courant que de passer subitement vers un Ã©tat diffÃ©rent alors la probabilitÃ© finale des Ã©vÃ¨nements courir et marcher est une somme pondÃ©rÃ©e des probabilitÃ©s prÃ©cÃ©dentes et de la probabilitÃ© courante Formellement une image ğ‘“ avec une magnitude moyenne de flux optiqueğ‘šğ‘“ contient un Ã©vÃ©nement courir si ğ‘“âˆ‘ ğ‘™=ğ‘“âˆ’â„ ğ‘¤ğ‘“âˆ’ğ‘™ â‹… ğ‘ƒğ‘ğ‘œğ‘¢ğ‘Ÿ ğ‘šğ‘™ > ğœ—ğ‘ğ‘œğ‘¢ğ‘Ÿ 6 oÃ¹ ğœ—ğ‘ğ‘œğ‘¢ğ‘Ÿ est le seuil de probabilitÃ© lâ€™Ã©vÃ¨nement courir â„ est le nombre dâ€™mages prÃ©cÃ©dentes Ã  considÃ©rer Chaque Ã©tat prÃ©cÃ©dent a un poids ğ‘¤ğ‘™ on a dÃ©fini â„ = 1 ğ‘¤0 = 0 8 et ğ‘¤1 = 0 2 ğ‘ƒğ‘ğ‘œğ‘¢ğ‘Ÿ ğ‘šğ‘™ est la probabilitÃ© dâ€™observer ğ‘šğ‘™ Elle est obtenue en comparant ğ‘šğ‘™ au modÃ¨le de magnitude obtenu Ã  partir de personnes qui marchent voir section 3 2 en utilisant la formule 4 Cette probabilitÃ© est seuillÃ©e pour dÃ©tecter lâ€™Ã©vÃ¨nement courir un seuil de 0 95 est choisi Ceci est justifiÃ© par le fait quâ€™il y a une probabilitÃ© de 0 95 pour une variable dâ€™Ãªtre entre ğœ‡âˆ’2ğœ et ğœ‡+2ğœ oÃ¹ ğœ‡ et ğœ sont respectivement la moyenne et lâ€™Ã©cart type de la loi Gaussienne Comme ğ‘ƒğ‘ğ‘œğ‘¢ğ‘Ÿ = 1 âˆ’ ğ‘ƒğ‘šğ‘ğ‘Ÿğ‘â„ lâ€™Ã©vÃ¨nement marcher se produit quand il nâ€™y a pas dâ€™Ã©vÃ¨nement courir et vice versa 4 2 Ã‰vÃ¨nements de rassemblement ou de sÃ©paration Pour la dÃ©tection des Ã©vÃ¨nements rassemblement et sÃ©paration on calcule la variance cir culaire ğ‘†0 ğ‘“ des orientations globales des groupes dans chaque image ğ‘“ selon lâ€™Ã©quation sui vante L Gaile et E Burt 1980 ğ‘†0 ğ‘“ = 1âˆ’ 1 ğ‘›ğ‘“ ğ‘›ğ‘“âˆ‘ ğ‘–=1 cos ğ‘‹ğ‘– ğ‘“ âˆ’ğ‘‹0 ğ‘“ 7 La variance ğ‘†0 ğ‘“ est comprise entre 0 et 1 inclus Si les angles sont identiques ğ‘†0 ğ‘“ sera Ã©gal Ã  0 Un ensemble dâ€™angles totalement opposÃ©s donnera une valeur de ğ‘†0 ğ‘“ Ã©gale Ã  1 Si la variance circulaire dÃ©passe un certain seuil ğ›½ on choisit ğ›½ = 0 3 dans notre implÃ©mentation on dÃ©duit la rÃ©alisation dâ€™une sÃ©paration et ou dâ€™un rassemblement On examine aussi la position et lâ€™orientation de chaque groupe par apport aux autres groupes afin de dÃ©cider prÃ©cisÃ©ment quel Ã©vÃ¨nement sâ€™est produit Si par exemple deux groupes proches sont orientÃ©s vers la mÃªme destination alors la probabilitÃ© de lâ€™Ã©vÃ©nement rassemblement sera grande Pour lâ€™Ã©vÃ¨nement sÃ©paration on distingue trois situations diffÃ©rentes 1 La division se produit dans un petit secteur et elle est temporaire câ€™est une dispersion locale RNTI E 19 346 Y BENABBAS et al a Un groupe avant sÃ©paration b Les groupes sÃ©parÃ©s FIG 6 â€“ DÃ©tection dâ€™une sÃ©paration 2 La division est plus longue dans le temps et les groupes sâ€™Ã©loignent câ€™est une sÃ©paration 3 Si la premiÃ¨re situation se produit lorsque la foule court alors câ€™est une Ã©vacuation Les probabilitÃ©s de fusion sÃ©paration dispersion locale et Ã©vacuation pour lâ€™image ğ‘“ notÃ©s respectivement ğ‘ƒğ‘“ğ‘¢ğ‘ ğ‘“ ğ‘ƒğ‘ ğ‘’ğ‘ğ‘“ ğ‘ƒğ‘‘ğ‘–ğ‘ ğ‘ğ‘“ ğ‘ƒğ‘’ğ‘£ğ‘ğ‘ğ‘“ sont nuls si la variance circulaire est infÃ© rieure Ã  un seuil Dans le cas contraire les probabilitÃ©s de fusion dispersion locale et sÃ©paration sont calculÃ©s en divisant le nombre dâ€™occurrences de chaque Ã©vÃ¨nement par leur nombre dâ€™oc currences total dans lâ€™image ğ‘“ Soient ğ‘ğ‘“ğ‘¢ğ‘ ğ‘“ ğ‘ğ‘ ğ‘’ğ‘ğ‘“ ğ‘ğ‘‘ğ‘–ğ‘ ğ‘ğ‘“ le nombre dâ€™occurrences des Ã©vÃ¨nements fusion sÃ©paration dispersion locale respectivement dans lâ€™image ğ‘“ La probabilitÃ© de fusion ğ‘ƒğ‘“ğ‘¢ğ‘ ğ‘“ Ã  lâ€™image ğ‘“ est calculÃ©e comme suit ğ‘ƒğ‘“ğ‘¢ğ‘ ğ‘“ = ğ‘ğ‘“ğ‘¢ğ‘ ğ‘“ ğ‘ğ‘“ğ‘¢ğ‘ ğ‘“ +ğ‘ğ‘ ğ‘’ğ‘ğ‘“ +ğ‘ğ‘‘ğ‘–ğ‘ ğ‘ğ‘“ 8 Finalement la probabilitÃ© dâ€™Ã©vacuation Ã  lâ€™image ğ‘“ notÃ©e ğ‘ƒğ‘’ğ‘£ğ‘ğ‘ğ‘“ est un cas particulier puisquâ€™il est conditionnÃ© par lâ€™Ã©vÃ¨nement courir en plus de lâ€™Ã©vÃ¨nement dispersion locale Par consÃ©quent sâ€™il y a un Ã©vÃ¨nement courir Ã  lâ€™image ğ‘“ alors ğ‘ƒğ‘‘ğ‘–ğ‘ ğ‘ğ‘“ est remplacÃ© par ğ‘ƒğ‘’ğ‘£ğ‘ğ‘ğ‘“ et ğ‘ğ‘‘ğ‘–ğ‘ ğ‘ğ‘“ est remplacÃ© par ğ‘ğ‘’ğ‘£ğ‘ğ‘ğ‘“ 5 ExpÃ©rimentations Lâ€™approche dÃ©crite dans les sections prÃ©cÃ©dentes a Ã©tÃ© Ã©valuÃ©e sur la base de vidÃ©os de PETSâ€™2009 Ces vidÃ©os incluent des sÃ©quences contenant diffÃ©rentes activitÃ©s de foule DiffÃ© rents scÃ©narios impliquant le calcul de la densitÃ© de foule comptage du nombre de personnes suivi dâ€™une seule personne dans une foule analyse de flux et dÃ©tection dâ€™Ã©vÃ¨nements haut niveau Un ensemble de donnÃ©es dâ€™apprentissage est aussi disponible il a Ã©tÃ© utilisÃ© pour la crÃ©ation des modÃ¨les de magnitude et dâ€™orientation de la scÃ¨ne Nous avons traitÃ© les sÃ©quences dâ€™analyse de flux et de reconnaissance des Ã©vÃ¨nements Ces sÃ©quences sont au format JPEG avec une rÃ©solution de 720Ã— 576 pixels et une cadence de 8 ips RNTI E 19 347 DÃ©tection dâ€™Ã©vÃ¨nements dans une scÃ¨ne de foule SÃ©quence Description SÃ©q 1 7 personnes se dÃ©placent en zigzag SÃ©q 2 Une foule se dÃ©place tout en Ã©vitant des obstacles hu mains SÃ©q 3 3 des groupes se fusionnent en un seul groupe SÃ©q 4 et 5 3 personnes circulent dans le sens inverse de la foule TAB 1 â€“ Description des sÃ©quences utilisÃ©es pour la dÃ©tection des flux multiples sÃ©quence Marcher Courir Dispersion locale SÃ©paration Fusion Ã‰vacuation SÃ©q 6 âˆ™ âˆ™ SÃ©q 7 âˆ™ âˆ™ âˆ™ SÃ©q 8 âˆ™ âˆ™ SÃ©q 9 âˆ™ âˆ™ âˆ™ âˆ™ TAB 2 â€“ Description des sÃ©quences utilisÃ©es pour la dÃ©tection dâ€™Ã©vÃ©nÃ©ments Les sÃ©quences dÃ©crites dans le tableau 1 ont Ã©tÃ© utilisÃ©es pour la dÃ©tection des flux mul tiples tandis que celles du tableau 2 contiennent les Ã©vÃ¨nements expÃ©rimentÃ©s La majoritÃ© des Ã©vÃ¨nements ont Ã©tÃ© dÃ©tectÃ©s avec succÃ¨s Quelques fausses dÃ©tections surviennent principa lement dues Ã  la mesure de profondeur qui donne des distances parfois imprÃ©cises entre les groupes et Ã  lâ€™ombre qui gÃ©nÃ¨re de faux groupes Le tableau 3 montre les mesures de prÃ©cision et de rappel pour les divers Ã©vÃ©nements expÃ©rimentÃ©s et qui montre que lâ€™approche donne des rÃ©sultats satisfaisants par comparaison Ã  la vÃ©ritÃ© terrain Marcher Courir Evacuation Dispersion locale Fusion SÃ©paration PrÃ©cision 97 23% 75 86% 69 09% 67 40% 59 14% 47 36% Rappel 96 17% 81 48% 82 60% 45 04% 45 32% 47 36% TAB 3 â€“ Performances du systÃ¨me pour chaque Ã©vÃ¨nement 6 Conclusions Les approches traditionnelles pour lâ€™analyse de comportement se focalisent gÃ©nÃ©ralement sur une seule personne La plupart de ces approches Ã©chouent sur les scÃ¨nes de foule Dans ce papier une approche dâ€™analyse globale pour la dÃ©tection des flux multiples et la dÃ©tection des Ã©vÃ¨nements liÃ©s aux foules a Ã©tÃ© proposÃ©e Certains Ã©vÃ¨nements sont aussi dÃ©tectÃ©s en analysant la relation spatiotemporelle entre les groupes de personne pour chaque image Trois catÃ©gories dâ€™Ã©vÃ¨nements sont visÃ©es course rassemblement et sÃ©paration de personnes Les expÃ©rimentations sur lâ€™Ã©chantillon de vidÃ©os PETSâ€™2009 ont montrÃ© que notre mÃ©thode est trÃ¨s prometteuse pour des scÃ¨nes de foules et des scÃ¨nes complexes Dans les travaux futurs RNTI E 19 348 Y BENABBAS et al nous appliquerons une mÃ©thode de suppression des ombres pour rÃ©duire lâ€™effet des ombres En plus nous prendrons en compte de lâ€™information de profondeur 2 5D ou 3D pour mesurer plus prÃ©cisÃ©ment les distances dans lâ€™espace Remerciements Ce travail a Ã©tÃ© rÃ©alisÃ© dans le cadre du projet ANR CAnADA 2007 2010 Analyse des comportements Anormaux Alerte DÃ©tection Action et le projet europÃ©en Miauce 2006 2009 FP6 Call 5 IST 2005 5 033715 RÃ©fÃ©rences Ali S et M Shah 17 22 June 2007 A Lagrangian particle dynamics approach for crowd flow segmentation and stability analysis IEEE Conference on Computer Vision and Pattern Recognition 2007 CVPR â€™07 1â€“6 Andrade E L S Blunsden et R B Fisher 2006a Hidden Markov models for optical flow analysis in crowds 18th International Conference on Pattern Recognition ICPRâ€™06 1 460â€“463 Andrade E L S Blunsden et R B Fisher 2006b Modelling crowd scenes for event detection 18th International Conference on Pattern Recognition ICPRâ€™06 175â€“178 Boghossian B et S Velastin 1999 Motion based machine vision techniques for the mana gement of large crowds Proceedings of ICECS â€™99 The 6th IEEE International Conference on Electronics Circuits and Systems 2 961â€“964 Cupillard F A Avanzi F Bremond et M Thonnat 2004 Video understanding for metro surveillance 2004 IEEE International Conference on Networking Sensing and Control 1 186â€“191 Davies A J H Yin et S Velastin 1995 Crowd monitoring using image processing Elec tronics Communication Engineering Journal 7 1 37â€“47 Harris C et M Stephens 1988 A combined corner and edge detector In Alvey Vision Conference pp 147â€“152 Hu M S Ali et M Shah 2008 Detecting global motion patterns in complex videos In ICPRâ€™08 International Conference on Pattern Recognition Ihaddadene N et C Djeraba 2008 Real time crowd motion analysis ICPR International Conference on Pattern Recognition Tampa Florida USA Kaewtrakulpong P et R Bowden 2001 An improved adaptive background mixture model for realtime tracking with shadow detection 2nd European Workshop on Advanced Video Based Surveillance Systems AVBS01 VIDEO BASED SURVEILLANCE SYSTEMS L Gaile G et J E Burt 1980 Directional Statistics Concepts and techniques in modern geography no 25 Norwich England Geo Abstracts Lin S F J Y Chen et H X Chao 2001 Estimation of number of people in crowded scenes using perspective transformation IEEE Transactions on Systems Man and Cybernetics Part A 31 6 645â€“654 RNTI E 19 349 DÃ©tection dâ€™Ã©vÃ¨nements dans une scÃ¨ne de foule Lucas B et T Kanade 1981 An iterative image registration technique with an application to stereo vision Proceedings of the International Joint Conference on Artificial Intelli gence 1 674â€“679 Ma R L Li W Huang et Q Tian 2004 On pixel count based crowd density estimation for visual surveillance IEEE Conference Cybernetics and Intelligent Systems 1 170â€“173 Marana A S Velastin L Costa et R Lotufo 1997 Estimation of crowd density using image processing IEEE Colloquium Image Processing for Security Applications Digest No 1997 074 11 1â€“11 8 Mehran R A Oyama et M Shah 2009 Abnormal crowd behavior detection using social force model IEEE Computer Society Conference on Computer Vision and Pattern Recog nition Rahmalan H M S Nixon et J N Carter 2006 On crowd density estimation for sur veillance In International Conference on Crime Detection and Prevention Shi J et C Tomasi 1994 Good features to track In IEEE Conference on Computer Vision and Pattern Recognition pp 593â€“600 Shyu M L Z X abd Min Chen et S C Chen 2008 Video semantic event concept de tection using a subspace based multimedia datamining framework IEEE transactions on multimedia ISSN 1520 9210 10 252â€“259 Wright J et R Pless 2005 Analysis of persistent motion patterns using the 3d structure tensor In WACV MOTION â€™05 Proceedings of the IEEE Workshop on Motion and Vi deo Computing WACV MOTIONâ€™05 Volume 2 Washington DC USA pp 14â€“19 IEEE Computer Society Summary Video surveillance systems are becoming more and more autonomous in the detection and the reporting of abnormal events This paper presents a method to detect major flows and events in crowd scenes These detections are performed using a Direction Model constructed from an online mixture of von Mises distributions applied to the orientation of the optical flow vectors Major flows are then detected by retrieving the most important orientations from the mixture Several crowd related events are also detected using a probabilistic model applied to the mean motion magnitude of the optical flow vectors on each frame of the scene In addition spatiotemporal relationship analysis of the crowd using the direction model according to the category of the event The results of processing on a video dataset are presented RNTI E 19 350 