 R√©duction de la complexit√© spatiale et temporelle du Compact Prediction Tree pour la pr√©diction de s√©quences Ted Gueniche Philippe Fournier Viger D√©partement d‚Äôinformatique Universit√© de Moncton 18 Antonine Maillet Moncton NB E1A 3E9 ted gueniche gmail com philippe fournier viger umoncton ca R√©sum√© La pr√©diction de s√©quences de symboles est une t√¢che ayant de mul tiples applications Plusieurs mod√®les de pr√©diction ont √©t√© propos√©s tels que DG All k order markov et PPM R√©cemment il a √©t√© montr√© qu‚Äôun nouveau mod√®le nomm√© Compact Prediction Tree CPT utilisant une structure en arbre et un algorithme de pr√©diction plus complexe offre des pr√©dictions plus exactes que plusieurs approches de la litt√©rature N√©anmoins une limite importante de CPT est sa complexit√© temporelle et spatiale √©lev√©e Dans cet article nous pal lions ce probl√®me en proposant trois strat√©gies pour r√©duire la taille et le temps de pr√©diction de CPT Les r√©sultats exp√©rimentaux sur 7 jeux de donn√©es r√©els montrent que le mod√®le r√©sultant nomm√© CPT+ est jusqu‚Äô√† 98 fois plus compact et est 4 5 fois plus rapide que CPT tout en conservant une exactitude tr√®s √©lev√©e par rapport √† All K order Markov DG Lz78 PPM et TDAG 1 Introduction Le probl√®me de pr√©diction de s√©quences est un probl√®me important en fouille de don n√©es d√©fini de la fa√ßon suivante Soit un alphabet Z = {e1 e2 em} contenant un en semble d‚Äô√©l√©ments symboles Une s√©quence est une suite d‚Äô√©l√©ments totalement ordonn√©e s = „Äài1 i2 in„Äâ o√π ik ‚àà Z 1 ‚â§ k ‚â§ n Un mod√®le de pr√©diction M est un mod√®le en tra√Æn√© avec un ensemble de s√©quences d‚Äôentra√Ænement Une fois entra√Æn√© le mod√®le peut √™tre utilis√© pour effectuer des pr√©dictions Une pr√©diction consiste √† pr√©dire le prochain √©l√©ment in+1 d‚Äôune s√©quence „Äài1 i2 in„Äâ en utilisant le mod√®le M La pr√©diction de s√©quences a des applications importantes dans une multitude de domaines tels que le pr√©chargement de pages Web Deshpande et Karypis 2004 Padmanabhan et Mogul 1996 la recommandation de pro duits de consommation la pr√©vision m√©t√©orologique et la pr√©diction des tendances du march√© boursier Un grand nombre de mod√®les de pr√©dictions ont √©t√© propos√©s pour la pr√©diction de s√© quences Un des mod√®le les plus connus est PPM Prediction by Partial Matching Cleary et Witten 1984 Ce mod√®le bas√© sur la propri√©t√© de Markov a engendr√© une multitude d‚Äôap proches d√©riv√©es telles que Dependancy Graph DG Padmanabhan et Mogul 1996 All k order Markov Pitkow et Pirolli 1999 et Transition Directed Acyclic Graph TDAG Laird et Saul 1994 Bien que des propositions ont √©t√© faites pour r√©duire la complexit√© temporelle 59 R√©duction de la complexit√© spatiale temporelle du Compact Prediction Tree et spatiale de ces mod√®les Begleiter et al 2004 l‚Äôexactitude de leurs pr√©dictions a subi peu d‚Äôam√©lioration D‚Äôautre part un certain nombre d‚Äôalgorithmes de compression ont √©t√© adapt√©s pour la pr√©diction de s√©quences tels que LZ78 Ziv et Lempel 1978 et Active Lezi Gopalrat nam et Cook 2007 De plus des algorithmes d‚Äôapprentissage machine comme les r√©seaux de neurones et la d√©couverte de r√®gles d‚Äôassociation s√©quentielles ont √©t√© employ√©s pour faire de la pr√©diction de s√©quences Fournier Viger et al 2012 Sun et Giles 2001 N√©anmoins ces mod√®les souffrent de limites importantes Premi√®rement la plupart d‚Äôentre eux partent de l‚Äôhy poth√®se Markovienne qu‚Äôun √©v√©nement ne d√©pend que de son pr√©d√©cesseur Or ce n‚Äôest pas le cas pour de nombreuses applications ce qui nuit √† l‚Äôexactitude des pr√©dictions Deuxi√®mement tous ces mod√®les sont construits avec perte d‚Äôinformation par rapport aux s√©quences d‚Äôentra√Æ nement Donc ils n‚Äôutilisent pas toute l‚Äôinformation disponible dans les s√©quences d‚Äôentra√Æne ment pour effectuer les pr√©dictions Pour pallier ces limites un mod√®le nomm√© Compact Prediction Tree CPT Gueniche et al 2013 a √©t√© r√©cemment propos√© Il utilise une structure en arbre pour compresser les s√© quences d‚Äôentra√Ænement sans perte ou avec une perte minime d‚Äôinformation De plus il emploie un algorithme de pr√©diction con√ßu pour tenir compte du bruit et de plusieurs √©v√©nements ant√© rieurs lors d‚Äôune pr√©diction plut√¥t que seulement le dernier Il a √©t√© montr√© que ce mod√®le peut obtenir des pr√©dictions jusqu‚Äô√† 12 % plus exactes que PPM DG et All K order markov sur des jeux de donn√©es provenant de divers domaines ce qui constitue un gain important N√©anmoins une limite de CPT est sa complexit√© temporelle et spatiale √©lev√©e Dans cet article nous pal lions ces probl√®mes en proposant trois strat√©gies pour r√©duire la taille et le temps de pr√©diction de CPT De plus nous pr√©sentons une comparaison exp√©rimentale avec davantage de mod√®les de pr√©diction de la litt√©rature All K order Markov DG Lz78 PPM et TDAG Les r√©sultats exp√©rimentaux sur 7 jeux de donn√©es r√©els montrent que le mod√®le r√©sultant nomm√© CPT+ est jusqu‚Äô√† 98 fois plus compact et est jusqu‚Äô√† 4 5 fois plus rapide que CPT De plus CPT+ conserve une exactitude tr√®s √©lev√©e par rapport aux autres approches de la litt√©rature Le reste de cet article est organis√© de la fa√ßon suivante La section 2 d√©crit bri√®vement le mod√®le CPT Les sections 3 et 4 proposent respectivement de nouvelles strat√©gies pour r√©duire la taille du mod√®le CPT et ses temps de pr√©diction La section 5 pr√©sente l‚Äô√©valuation exp√©rimentale avec plusieurs jeux de donn√©es et les principaux mod√®les de pr√©dictions de la litt√©rature Finalement la section 6 est d√©di√©e √† la conclusion et aux travaux futurs 2 Le Compact Prediction Tree Le CPT Compact Prediction Tree est un mod√®le de pr√©diction r√©cemment propos√© Gue niche et al 2013 Ses principales caract√©ristiques distinctives sont 1 qu‚Äôil stocke sous forme compress√©e l‚Äôensemble des s√©quences d‚Äôentra√Ænement sans perte ou avec une perte minime d‚Äôinformation et 2 qu‚Äôil utilise une mesure de similarit√© pour identifier les s√©quences simi laires √† une s√©quence √† pr√©dire pour faire une pr√©diction Cette mesure est tol√©rante au bruit ce qui permet √† CPT de pr√©dire les prochains √©l√©ments de sous s√©quences qui n‚Äôont pas √©t√© vues dans les s√©quences d‚Äôentra√Ænement alors que d‚Äôautres approches plus strictes telles que PPM et All K order markov ne peuvent pas faire de pr√©diction dans ce cas Le mod√®le CPT est d√©fini par deux processus un processus d‚Äôentra√Ænement et un processus de pr√©diction 60 T Gueniche et al 2 1 Le processus d‚Äôentra√Ænement Le processus d‚Äôentra√Ænement g√©n√®re trois structures distinctes √† partir des s√©quences d‚Äôen tra√Ænement 1 un Arbre de Pr√©diction AP 2 un Dictionnaire de S√©quences DS et 3 un Index Invers√© II Pendant l‚Äôentra√Ænement les s√©quences sont consid√©r√©es les unes apr√®s les autres pour construire incr√©mentalement ces trois structures √Ä titre d‚Äôexemple la figure 1 illustre la cr√©ation des structures de CPT par insertion successive des s√©quences s1 = „ÄàA B C„Äâ s2 = „ÄàA B„Äâ s3 = „ÄàA B D C„Äâ s4 = „ÄàB C„Äâ et s5 = „ÄàE A B A„Äâ o√π l‚Äôal phabet Z = {A B C D E} est utilis√© A B C s1 s1 A 1 B 1 C 1 root Index invers√© Arbre de pr√©diction Dictionnaire de s√©quences 1 Insertion de ‚å©ùë® ùë© ùë™‚å™ Index invers√© A B C s1 s1 s2 A 1 1 B 1 1 C 1 0 s2 Arbre de pr√©diction Dictionnaire de s√©quences root 2 Insertion de ‚å©ùë® ùë©‚å™ A B C s1 s1 s2 s3 A 1 1 1 B 1 1 1 C 1 0 1 D 0 0 1 s2 s3 D C Index invers√© Arbre de pr√©diction Dictionnaire de s√©quences root 3 Insertion de ‚å©ùë® ùë© ùë´ ùë™‚å™ 4 Insertion de ‚å©ùë© ùë™‚å™ 5 Insertion de ‚å©ùë¨ ùë® ùë© ùë®‚å™ A B C s1 s1 s2 s3 s4 A 1 1 1 0 B 1 1 1 1 C 1 0 1 1 D 0 0 1 0 s2 s3 B C s4 D C Index invers√© Arbre de pr√©diction Dictionnaire de s√©quences root A B C s1 s1 s2 s3 s4 s5 A 1 1 1 0 1 B 1 1 1 1 1 C 1 0 1 1 0 D 0 0 1 0 0 E 0 0 0 0 1 s2 s3 B C A B s4 s5 D C Index invers√© Arbre de pr√©diction Dictionnaire de s√©quences root E A FIG 1 ‚Äì Construction des structures de CPT L‚ÄôArbre de Pr√©diction est une forme d‚Äôarbre pr√©fixe alias trie Chacun des noeuds de l‚Äôarbre repr√©sente un √©l√©ment et chacune des s√©quences d‚Äôentra√Ænement est repr√©sent√©e par un chemin partant de la racine de l‚Äôarbre et se terminant par un noeud interne de l‚Äôarbre ou une feuille La construction de cet arbre a une basse complexit√© Ins√©rer une s√©quence de m √©l√©ments demande de parcourir cr√©er au plus m noeuds La construction compl√®te de l‚Äôarbre est O n o√π n est le nombre de s√©quences √† ins√©rer Tout comme un arbre pr√©fixe cet arbre est une repr√©sentation compacte des s√©quences d‚Äôentra√Ænement car les s√©quences partageant un pr√©fixe commun partagent un chemin dans l‚Äôarbre Par exemple √† la figure 1 les s√©quences s1 s2 et s3 partagent le m√™me chemin correspondant au pr√©fixe „ÄàA B„Äâ Dans le pire cas le gain spatial offert par cette compression est nul mais en pratique tout d√©pendant de la densit√© et de 61 R√©duction de la complexit√© spatiale temporelle du Compact Prediction Tree la similarit√© des s√©quences du jeu de donn√©es utilis√© l‚Äôarbre peut offrir une r√©duction spatiale tr√®s importante allant jusqu‚Äô√† 98% Gueniche et al 2013 Le Dictionnaire de S√©quences est une structure qui permet d‚Äôextraire chacune des s√© quences d‚Äôentra√Ænement de l‚Äôarbre de pr√©diction Lors de la construction du mod√®le CPT un identifiant unique est assign√© √† chaque s√©quence Il est √©gal √† 1 pour la premi√®re s√©quence ins√©r√©e d√©not√© s1 et est incr√©ment√© d‚Äôun pour chaque s√©quence subs√©quente s2 s3 Le dictionnaire de s√©quences associe chaque identifiant de s√©quence sa √† un pointeur vers un noeud de l‚Äôarbre Ce noeud repr√©sente le dernier √©l√©ment de la s√©quence sa dans l‚Äôarbre Gr√¢ce √† cette structure il est possible de parcourir chaque s√©quence d‚Äôentra√Ænement dans l‚Äôarbre de pr√©diction du dernier au premier √©l√©ment L‚ÄôIndex Invers√© permet d‚Äôidentifier rapidement dans quelles s√©quences appara√Æt un en semble d‚Äô√©l√©ments d‚Äôune s√©quence √† pr√©dire L‚Äôindex invers√© contient un vecteur de bits ve pour chaque √©l√©ment e de l‚Äôalphabet Z pr√©sent dans les s√©quences d‚Äôentra√Ænement Le k i√®me bit d‚Äôun vecteur de bit ve prend la valeur 1 si l‚Äô√©l√©ment e appara√Æt dans la s√©quence sk sinon il prend la valeur 0 Par exemple √† la figure 1 le vecteur de bit de l‚Äô√©l√©ment C apr√®s l‚Äôinsertion des s√©quences s1 s2 s3 s4 et s5 est 10110 car C appara√Æt dans les s√©quences s1 s3 et s4 L‚Äôindex invers√© est utilis√© pour d√©terminer rapidement les s√©quences d‚Äôentra√Ænement contenant un ensemble d‚Äô√©l√©ments d‚Äôune s√©quence √† pr√©dire Cela est r√©alis√© en faisant l‚Äôintersection des vecteurs de bits des √©l√©ments Par exemple d√©terminer l‚Äôensemble des s√©quences contenant les √©l√©ments A et C est r√©alis√© par l‚Äôop√©ration 11101 ‚àß 10110 donnant le r√©sultat 10000 au trement dit {s1} Gr√¢ce √† l‚Äôindex invers√© cette t√¢che est tr√®s rapide O i o√π i est le nombre d‚Äô√©l√©ments dans l‚Äôensemble 2 2 Le processus de pr√©diction Le processus de pr√©diction de CPT utilise les trois structures d√©crites pr√©c√©demment Soit une s√©quence s = „Äài1 i2 in„Äâ de n √©l√©ments et y un nombre entier repr√©sentant le nombre d‚Äô√©l√©ments de s √† consid√©rer pour faire une pr√©diction Le suffixe de taille y de s d√©not√© Py s est d√©fini comme √©tant Py s = „Äàin‚àíx+1 in‚àíx+2 in„Äâ La pr√©diction du prochain √©l√©ment de s est effectu√©e de la fa√ßon suivante CPT identifie tout d‚Äôabord les s√©quences similaires √† Py s c √† d qui contiennent les derniers y √©l√©ments de Py s dans n‚Äôimporte quel ordre et positions Puis pour chaque s√©quence similaire CPT consid√®re son cons√©quent Le cons√© quent d‚Äôune s√©quence u est la sous s√©quence d√©butant apr√®s le dernier √©l√©ment en commun avec Py s jusqu‚Äô√† la fin de u Chaque √©l√©ment e dans un de ces cons√©quents est ensuite stock√© dans une structure nomm√© Table de Compte TC avec son nombre d‚Äôoccurrences ce nombre est une estimation de la probabilit√© P e|Py s L‚Äô√©l√©ment ayant le plus grand nombre d‚Äôoc currences est l‚Äô√©l√©ment pr√©dit par CPT La mesure de similarit√© utilis√©e pour d√©terminer les s√©quences similaires est de nature stricte mais est rel√¢ch√©e dynamiquement par le processus de pr√©diction pour deux raisons Premi√®rement avec une mesure de similarit√© trop stricte une s√©quence √† pr√©dire peut n‚Äô√™tre similaire √† aucune s√©quence d‚Äôentra√Ænement et donc aucune pr√©diction n‚Äôest possible Deuxi√®mement une mesure de similarit√© trop stricte ne permet pas de consid√©rer qu‚Äôune s√©quence peut √™tre partiellement similaire √† une autre Or dans les ap plications r√©elles il y a souvent des √©l√©ments pr√©sents dans les s√©quences qui sont du bruit Pour rel√¢cher la mesure de similarit√© CPT suppose qu‚Äôun ou plusieurs √©l√©ments pr√©sents dans le suffixe de la s√©quence √† pr√©dire sont du bruit et qu‚Äôils peuvent √™tre ignor√©s lors du calcul de similarit√© Le calcul de similarit√© pour un suffixe Py s est fait par niveau o√π √† chaque 62 T Gueniche et al niveau k = 1 2 |Py s | ‚àí 1 toutes les sous s√©quences de taille |Py s | ‚àí k de Py s sont g√©n√©r√©es Chacune des sous s√©quence u est utilis√©e pour trouver les s√©quences similaires dans l‚Äôensemble de s√©quences d‚Äôentra√Ænement et pour mettre √† jour la TC Ce rel√¢chement de la mesure de similarit√© se poursuit pour la s√©quence √† pr√©dire d‚Äôun niveau √† l‚Äôautre tant que TC n‚Äôa pas √©t√© mise √† jour un nombre minimum de fois 3 Strat√©gies de compression de l‚Äôarbre de pr√©diction Bien que CPT offre des pr√©dictions plus exactes que les principaux mod√®les de pr√©diction de la litt√©rature selon une √©tude ant√©rieure Gueniche et al 2013 une limite importante de CPT est sa complexit√© spatiale Il a √©t√© montr√© que la taille des structures de CPT est inf√©rieure √† All k order Markov mais demeure nettement sup√©rieures √† d‚Äôautres mod√®les comme DG et PPM L‚Äôarbre de pr√©diction √©tant la structure la plus imposante de CPT nous proposons ci apr√®s deux strat√©gies pour r√©duire sa taille Strat√©gie 1 Compressions des Cha√Ænes Fr√©quentes CCF Certaines r√©p√©titions peuvent √™tre identifi√©es dans les s√©quences d‚Äôentra√Ænement D√©pendamment du jeu de donn√©es ces r√©p√© titions peuvent √™tre nombreuses et fr√©quentes La compression des cha√Ænes fr√©quentes consiste √† identifier les sous cha√Ænes fr√©quentes d‚Äô√©l√©ments apparaissant dans les s√©quences d‚Äôentra√Æne ment puis √† remplacer les sous cha√Ænes fr√©quentes par des √©l√©ments individuels Soit une s√©quence s = „Äài1 i2 in„Äâ Une s√©quence c = „Äàjm+1 jm+2 jm+k„Äâ est une sous chaine de s d√©not√© c v s si et seulement si 1 ‚â§ m ‚â§ m+ k ‚â§ n Pour un ensemble de s√©quences d‚Äôentra√Ænement S une sous cha√Æne d est fr√©quente si |{t|t ‚àà S‚àßd v t}| >minsup pour un seuil minsup fix√© par l‚Äôutilisateur La compression des cha√Ænes fr√©quentes est effectu√©e pendant la phase d‚Äôentra√Ænement de CPT en trois √©tapes 1 identifier les cha√Ænes fr√©quentes dans l‚Äôensemble des s√©quences d‚Äôen tra√Ænement 2 cr√©er un nouvel √©l√©ment dans l‚Äôalphabet Z pour repr√©senter chaque sous cha√Æne fr√©quente et 3 remplacer les sous cha√Ænes fr√©quentes par l‚Äô√©l√©ment correspondant lors de la construction de l‚Äôarbre de pr√©diction de CPT L‚Äôidentification de s√©quences fr√©quentes dans un ensemble de s√©quences est un probl√®me populaire en fouille de donn√©es pour lequel un grand nombre d‚Äôalgorithmes ont √©t√© propos√©s Pour cette t√¢che nous avons adapt√© un des algorithmes les plus performants nomm√© PrefixS pan Pei et al 2001 afin de ne d√©couvrir que les s√©quences fr√©quentes d‚Äô√©l√©ments cons√© cutifs sous cha√Ænes De plus nous avons ajout√© la contrainte que les sous cha√Ænes fr√©quentes doivent respecter des contraintes de longueur minimale minSize et maximale maxSize deux param√®tres Les sous cha√Ænes fr√©quentes identifi√©es sont stock√©es dans une nouvelle structure nomm√©e Dictionnaire des cha√Ænes fr√©quentes DCF Cette structure associe un nouvel √©l√©ment non pr√©sent dans l‚Äôalphabet Z dans les s√©quences d‚Äôentra√Ænement √† chaque sous cha√Æne fr√©quente Le DCF permet de rapidement convertir une sous cha√Æne en son √©l√©ment correspondant et vice versa Lors de l‚Äôinsertion des s√©quences d‚Äôentra√Ænement dans l‚Äôarbre de pr√©diction le DCF est utilis√© pour remplacer chaque sous cha√Æne par son √©l√©ment correspondant √Ä titre d‚Äôexemple l‚Äôillustration 1 de la figure 2 affiche la compression de l‚Äôarbre de pr√© diction de l‚Äôillustration 5 de la figure 1 par la strat√©gie CCF La sous cha√Æne fr√©quence „ÄàA B„Äâ a √©t√© remplac√©e par un nouveau symbole x r√©duisant le nombre de noeuds de l‚Äôarbre de pr√© diction 63 R√©duction de la complexit√© spatiale temporelle du Compact Prediction Tree La strat√©gie de compression de s√©quences CCF a un effet seulement sur l‚Äôarbre de pr√© diction o√π son nombre de noeuds et sa hauteur tendent √† diminuer grandement La strat√©gie CCF est transparente pour le processus de pr√©diction de CPT En effet lors de l‚Äôextraction de s√©quences similaires les branches de l‚Äôarbre de pr√©diction s√©lectionn√©es sont d√©compress√©es √† la vol√©e par DCF 1 Application de la strat√©gie CCF 2 Application des strat√©gies CCF et CBS x C s1 s1 s2 s3 s4 s5 A 1 1 1 0 1 B 1 1 1 1 1 C 1 0 1 1 0 D 0 0 1 0 0 E 0 0 0 0 1 s2 s3 B C x s4 s5 D C Index invers√© Arbre de pr√©diction Dictionnaire de s√©quences root E A x = AB s1 s2 s3 s4 s5 A 1 1 1 0 1 B 1 1 1 1 1 C 1 0 1 1 0 D 0 0 1 0 0 E 0 0 0 0 1 Index invers√© x = AB x C s1 s2 s3 BC s4 s5 DC Arbre de pr√©diction root ExA Dictionnaire de s√©quences FIG 2 ‚Äì Application des strat√©gies de compression de l‚Äôarbre CCF et CBS Strat√©gie 2 Compressions des Branches Simples CBS La compression des branches simples est une strat√©gie de compression intuitive et efficiente pour r√©duire la taille de l‚Äôarbre de pr√©diction Une branche simple est une branche qui m√®ne √† une seule feuille Chaque noeud d‚Äôune branche simple a donc entre 0 et 1 noeud fils La strat√©gie CBS consiste √† remplacer chaque branche simple par un seul noeud repr√©sentant son chemin vers la feuille du d√©but √† la fin Par exemple l‚Äôillustration 2 de la figure 2 illustre l‚Äôarbre de pr√©diction de l‚Äôexemple apr√®s l‚Äôapplication des strat√©gies CCF et CBS La strat√©gie CBS a respectivement remplac√© les branches simples D ‚àí C B ‚àí C et E ‚àí x‚àíA par des noeuds uniques DC BC et ExA L‚Äôidentification et le remplacement de branches simples sont faits en un seul parcours de l‚Äôarbre de pr√©diction L‚Äôindex invers√© et le dictionnaire de s√©quences n‚Äô√©tant pas influenc√©s par cette approche le seul changement au processus de pr√©diction est la d√©compression dynamique des branches simples lorsque n√©cessaire La complexit√© de ce remplacement est de O n 1‚àí t o√π s est le nombre de s√©quence et t le taux de recouvrement de l‚Äôarbre ce dernier est d√©fini comme le "ratio" de noeuds qui partagent plusieurs s√©quences par le nombre total de noeuds dans l‚Äôarbre 4 Strat√©gie de r√©duction des temps de pr√©diction Strat√©gie 3 Pr√©diction avec r√©duction du Bruit Am√©lior√© PBA Tel qu‚Äôexpliqu√© pr√© c√©demment pour pr√©dire le prochain √©l√©ment sn + 1 d‚Äôune s√©quence s = „Äài1 i2 in„Äâ CPT utilise le suffixe de taille y de s d√©not√© Py s les y derniers √©l√©ments de s o√π y est un pa ram√®tre propre √† chaque jeu de donn√©e CPT pr√©dit le prochain √©l√©ment de s en parcourant les s√©quences similaires √† son suffixe Py s La recherche de s√©quences similaires est rapide O y Toutefois le m√©canisme de r√©duction du bruit lors des pr√©dictions d√©crit √† la section 2 64 T Gueniche et al ne l‚Äôest pas car il requiert de consid√©rer non seulement Py s pour une pr√©diction mais aussi toutes les sous s√©quences de Py s de taille t > k Plus y et k sont grands plus le nombre de sous s√©quences √† consid√©rer l‚Äôest aussi et donc le temps de pr√©diction Lors d‚Äôune t√¢che de pr√©diction certains √©l√©ments dans une s√©quence √† pr√©dire peuvent √™tre consid√©r√©s comme du bruit si leur simple pr√©sence affecte de fa√ßon n√©gative le r√©sultat de la pr√©diction La strat√©gie PBA se base sur l‚Äôhypoth√®se que le bruit observ√© dans une s√©quence est constitu√© des √©l√©ments ayant une faible fr√©quence o√π la fr√©quence d‚Äôun √©l√©ment est le nombre de s√©quences d‚Äôen tra√Ænement contenant l‚Äô√©l√©ment Pour cette raison PBA enl√®ve seulement les √©l√©ments qui ont une faible fr√©quence pendant la phase de pr√©diction Puisque la d√©finition du bruit de CPT+ est plus restrictive que celle de CPT un moins grand nombre de sous s√©quences sont consid√© r√©es Cette r√©duction √† un impact positif et tangible sur les temps de calculs tel que pr√©sent√©s dans notre √©valuation exp√©rimentale section 5 Le pseudo code illustrant la strat√©gie PBA est pr√©sent√© ci apr√®s Algorithme 1 L‚Äôalgorithme prend en param√®tres le pr√©fixe Py s √† pr√©dire les autres structures de CPT un taux de bruit et un nombre minimum de mise √† jour √† faire √† la TC pour faire une pr√©diction Le taux de bruit repr√©sente le pourcentage d‚Äô√©l√©ments dans une s√©quence qui doivent √™tre consid√©r√©s comme du bruit un taux de bruit de 0 indique que les s√©quence n‚Äôont pas de bruit alors qu‚Äôun taux de bruit de 0 4 signifie que 40% des √©l√©ments d‚Äôune s√©quence pourrait √™tre du bruit PBA est r√©cursive de nature et consid√®re un nombre minimal de sous s√©quences d√©riv√©es de Py s pour faire une pr√©diction Le bruit est d‚Äôabord retir√© de chaque sous s√©quence Puis la TC est mise √† jour Lorsque le nombre minimal de mise √† jour est atteint une pr√©diction est faite comme dans CPT en utilisant la TC La strat√©gie PBA est une g√©n√©ralisation de la strat√©gie de r√©duction du bruit utilis√©e par CPT En effet selon les param√®tres utilis√©s il est possible de reproduire le fonctionnement original de CPT Les trois contributions principales apport√©es par PBA sont l‚Äôimposition d‚Äôun nombre minimal de mise √† jour de la TC pour faire une pr√©diction la d√©finition du bruit bas√© sur la fr√©quence d‚Äôun √©l√©ment et la r√©duction relative du bruit par rapport √† la longueur de la s√©quence Algorithme 1 L‚Äôalgorithme de pr√©diction avec PBA input PS le suffixe Ps CPT les structures de CPT TB le taux de bruit output Seq un ou plusieurs √©l√©ments pr√©dits file ajouter PS while nombreMiseAjour < minNombreMiseAJourTC ‚àß file nonVide do suffixe = file prochain elementsBruit = selectionnerElementsMoinsFrequents TB foreach elementBruit ‚àà elementsBruit do suffixeSansBruit = copierSuffixeSansBruit suffixe elementBruit if suffixeSansBruit length > 1 then file ajouter suffixeSansBruit end mettreAJourCountTable CPT countTable suffixeSansBruit nombreMiseAjour++ end retourne faireUnePrediction CPT countTable end 65 R√©duction de la complexit√© spatiale temporelle du Compact Prediction Tree 5 √âvaluation exp√©rimentale Nous avons effectu√© une s√©rie d‚Äôexp√©riences pour comparer la performance de CPT+ CPT et les principaux mod√®les de pr√©diction de la litt√©rature All K order Markov DG Lz78 PPM et TDAG Pour impl√©menter CPT+ nous avons obtenu et modifi√© le code source propos√© dans l‚Äôarticle original de CPT Gueniche et al 2013 Pour permettre la reproduction des exp√©riences le code source des mod√®les et jeux de donn√©es sont fournis √† l‚Äôadresse goo gl LE4uYO Tous les mod√®les sont impl√©ment√©s en Java 8 Les exp√©riences ont √©t√© r√©alis√©es sur une machine dot√©e d‚Äôun processeur deux coeurs Intel i5 de 4√®me g√©n√©ration avec 8 Go de m√©moire vive et un SSD en SATA 600 Tous les mod√®les de pr√©diction utilis√©s ont √©t√© configur√©s empiriquement pour tenter de donner des valeurs optimales √† chacun de leurs para m√®tres PPM et LZ78 n‚Äôont pas de param√®tres DG et AKOM ont respectivement une fen√™tre de 4 et un ordre de 5 finalement par soucis d‚Äôespace TDAG √† une hauteur maximale de 6 CPT √† 4 param√®tres et CPT+ en a 8 leurs valeurs sont elles aussi d√©termin√©es via une exploration exp√©rimentale de l‚Äôespace de valeurs possibles Ces valeurs sont accessible dans les fichiers sources du projet Les param√®tres propres √† l‚Äôexp√©rience se limitent √† la longueur minimale et maximale des s√©quences utilis√©es la taille du suffixe √† consid√©rer pour une s√©quence √† pr√©dire et la quantit√© d‚Äô√©l√©ments √† pr√©dire pour chacune des s√©quences Des jeux de donn√©es ayant des caract√©ristiques vari√©es ont √©t√© utilis√©s cf Table 1 s√© quences courtes longues s√©quences denses √©parses petit grands alphabets et divers types de donn√©es Les jeux de donn√©es BMS Kosarak MSNBC et FIFA consistent en des s√©quences de pages Web visit√©es par des utilisateurs sur un site Web Dans ce sc√©nario les mod√®les de pr√© diction sont appliqu√©s pour pr√©dire la prochaine page Web que visitera chaque utilisateur Le jeu de donn√©es SIGN est un ensemble de phrases exprim√©es en langage des signes transcrites √† partir de vid√©os Bible Word et Bible Char sont deux jeux de donn√©es qui proviennent de la Bible livre religieux le premier est l‚Äôensemble des phrases d√©coup√©es en mots et le second est l‚Äôensemble des phrases d√©coup√©es en caract√®res Pour l‚Äô√©valuation des pr√©dictions des mod√®les une pr√©diction est soit un succ√®s un √©chec ou une abstention si un mod√®le ne peut effectuer une pr√©diction Deux mesures sont utili s√©es La couverture est le nombre d‚Äôabstentions divis√© par le nombre de s√©quences √† pr√©dire L‚Äôexactitude alias pr√©cision le nombre de succ√®s divis√© par le nombre de s√©quences √† pr√©dire Nom Nombre des√©quence √âl√©ments uniques Longueur moyenne Type de donn√©es BMS 15 806 495 6 01 Pages Web KOSARAK 638 811 39 998 11 64 Pages Web FIFA 573 060 13 749 45 32 Pages Web MSNBC 250 697 17 3 28 Pages Web SIGN 730 267 93 00 Langage BIBLE Word 42 436 76 18 93 Phrases BIBLE Char 32 502 75 128 35 Caract√®res TAB 1 ‚Äì Jeux de donn√©es 66 T Gueniche et al Exp√©rience 1 comparaisons des optimisations Dans cette premi√®re exp√©rience nous avons tout d‚Äôabord √©valu√© les am√©liorations spatiales pr√©sent√©es √† la section 3 en terme de taux de compression et de temps de calcul √† l‚Äôentra√Ænement Les autres mesures de performance telles que le temps de pr√©diction la couverture et l‚Äôexactitude ne sont pas affect√©es par la compression de l‚Äôarbre de pr√©diction Pour un arbre de pr√©diction A avec s noeuds avant com pression et s2 noeuds apr√®s compression le taux de compression tca de A est d√©fini comme tc = 1‚àí s2 s et est compris entre 0 0 et 1 0 non inclusivement Plus la valeur est haute plus la compression est importante Les deux strat√©gies de compression sont √©valu√©es d‚Äôabord indi viduellement d√©not√©es CCF et CBS puis en conjonction d√©not√© CPT+ Toute compression permet d‚Äôobtenir un gain spatial au prix d‚Äôun co√ªt temporel La figure 3 pr√©sente cette relation pour chacune des strat√©gies de compression 0 1 1 10 100 BMS SIGN MSNBC Bible word Bible char Kosarak FIFA T em p s d 'e n tr a√Æ n em en t s Temps d'entra√Ænement CCF CBS CPT+ 0 00% 10 00% 20 00% 30 00% 40 00% 50 00% 60 00% 70 00% 80 00% 90 00% 100 00% BMS Sign MSN Bible word Bible char Kosarak FIFA T au x d e co m p re ss io n % Taux de compression CCF CBS CPT+ FIG 3 ‚Äì Taux de compression et temps d‚Äôentra√Ænement des strat√©gies de compression Les r√©sultats pr√©sent√©s √† la figure 3 montrent que le taux de compression de l‚Äôarbre varie selon le jeu de donn√©es de 58 90% √† 98 65% CCF offre un taux de compression moyen de 48 55% avec un faible √©cart type de 6 7% alors que CBS √† un taux de compression moyen de 77 87% avec un √©cart type beaucoup plus prononc√© de 15 9% L‚Äôefficacit√© de CBS est d√©pen dante au jeu de donn√©es dans le cas de MSNBC qui est le jeu de donn√©es le moins affect√© par les strat√©gies de compression la faible cardinalit√© de son alphabet permet √† MSNBC d‚Äô√™tre naturellement compress√© gr√¢ce au fort recouvrement des branches de son arbre de pr√©diction En effet MSNBC ne poss√®de que 17 √©l√©ments uniques et m√™me si la taille moyenne des s√© quences ressemble √† celle des autres jeux de donn√©es la taille de son arbre avant compression est tr√®s petite Le jeu de donn√©es o√π les strat√©gies de compression CCF et CBS sont les plus effectives est SIGN SIGN a un tr√®s faible nombre de s√©quences mais chacune d‚Äôelle est tr√®s longue en moyenne 93 √©l√©ments Ces caract√©ristiques font en sorte que son arbre de pr√©dic tion a un faible taux de recouvrement et donc une importante partie de ses noeuds n‚Äôont qu‚Äôun seul fils ce qui rend ce jeu de donn√©es un candidat id√©al pour la strat√©gie CBS CBS offre un taux de compression de 98 60 % pour SIGN La figure 3 pr√©sente √©galement les temps d‚Äôentra√Ænement engendr√©s par les deux strat√©gies de compression de CPT CBS et CCF La mesure utilis√©e est un facteur multiplicatif du temps d‚Äôentra√Ænement Par exemple un facteur de x pour CBS signifie que CBS a eu une phase d‚Äôentra√Ænement x fois plus longue Pour tous les jeux de donn√©es √† l‚Äôexception de SIGN CBS est plus rapide que CCF Il est int√©ressant d‚Äôobserver que le temps pris par la combinaison des deux strat√©gies de compression n‚Äôest pas simplement une addition de leur co√ªt d‚Äôentra√Ænement 67 R√©duction de la complexit√© spatiale temporelle du Compact Prediction Tree CBS et CCF sont appliqu√©s ind√©pendamment √† CPT et pourtant l‚Äôutilisation de CBS r√©duit les temps de calcul de CCF gr√¢ce √† une diminution du nombre de branches qui ont besoin d‚Äô√™tre compress√©es Nous avons √©galement √©valu√© le gain en temps de pr√©diction et l‚Äôexactitude pr√©cision obtenue en appliquant la strat√©gie PBA La figure 4 gauche illustre les temps de pr√©diction de CPT+ avec CBA et ceux de CPT Les gains temporels sont importants pour la plupart des jeux de donn√©es notamment pour SIGN et MSNBC o√π les temps d‚Äôentra√Ænement sont jusqu‚Äô√† 4 5 fois moindres Pour les jeux de donn√©es Bible Word et FIFA les temps de pr√©diction sont plus √©lev√©s pour obtenir un gain en exactitude comme le montre la figure 4 droite L‚Äôeffet de CBA sur l‚Äôexactitude des pr√©dictions est positif pour tous les jeux de donn√©es sauf MSNBC Cette am√©lioration s‚Äô√©l√®ve jusqu‚Äô√† 5 47% dans le cas de Bible Word CBA se montre donc une strat√©gie effective pour √† la fois r√©duire les temps de pr√©diction et augmenter l‚Äôexactitude des pr√©dictions 0 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 1 BMS SIGN MSNBC Bible word Bible char Kosarak FIFA T em p s d e p r√© d ic ti on s CPT+ CPT 0 10 20 30 40 50 60 70 80 BMS SIGN MSNBC Bible word Bible char Kosarak FIFA P r√© ci si on % CPT+ CPT FIG 4 ‚Äì Gains en temps de pr√©diction et exactitude avec l‚Äôajout de PBA Exp√©rience 2 Mise √† l‚Äô√©chelle Nous avons √©galement compar√© la complexit√© spatiale de CPT+ avec ses deux strat√©gies de compression avec celle de CPT et All K order Markov DG Lz78 PPM et TDAG en termes de mise √† l‚Äô√©chelle par rapport au nombre de s√©quences Les deux seuls jeux de donn√©es utilis√©s sont FIFA et Kosarak √† cause de leur grand nombre de s√©quences 573 060 et 638 811 respectivement L‚Äôaccroissement du nombre de s√©quences dans cette exp√©rience est quadratique et s‚Äôarr√™te √† 128 000 s√©quences d√ª aux √©normes temps de calcul requis pour r√©aliser chaque exp√©rience La figure 5 pr√©sente les r√©sultats Le taux de compression de CPT+ tend √† baisser tr√®s l√©g√®rement avec l‚Äôaccroissement du nombre de s√© quences ce ph√©nom√®ne est caus√© par un recouvrement de plus en plus important des branches dans l‚Äôarbre de pr√©diction car la taille de l‚Äôalphabet √©tant constante plus de s√©quences sont utilis√©es et plus de branches s‚Äôunifient Les mod√®les DG et PPM ont une croissance lin√©aire car ils sont bas√©s sur la taille de l‚Äôalphabet et indirectement sur le nombre de s√©quences d‚Äôen tra√Ænement Les autres mod√®les ont tous une croissance beaucoup plus importante que DG et PPM notamment TDAG et LZ78 Exp√©rience 3 Comparaison avec les autres mod√®les de pr√©diction Dans l‚Äôexp√©rience 1 nous avons compar√© l‚Äôexactitude des pr√©dictions de CPT+ avec celle de CPT afin d‚Äô√©valuer la contribution de la strat√©gie PBA Dans cette exp√©rience nous effec tuons une comparaison de l‚Äôexactitude celle des autres principaux mod√®les de pr√©diction de la litt√©rature All K order Markov DG Lz78 PPM et TDAG sur les m√™mes jeux de donn√©es Il est √† noter que nous ajoutons dans cette comparaison deux mod√®les de pr√©dictions Lz78 et TDAG qui n‚Äôont pas √©t√© utilis√©s dans l‚Äôarticle original proposant CPT Chaque mod√®le de 68 T Gueniche et al 100 1 000 10 000 100 000 1 000 000 10 000 000 100 000 000 T ai ll e e n no eu ds Nombre de s√©quences FIFA DG TDAG Mark1 LZ78 CPT CPT+ 100 1 000 10 000 100 000 1 000 000 10 000 000 100 000 000 T ai ll e e n no eu ds Nombre de s√©quences Kosarak FIG 5 ‚Äì Mise √† l‚Äô√©chelle des mod√®les de pr√©diction pr√©diction est entra√Æn√© et test√© en validation crois√©e √† k plis avec k = 14 pour assurer une faible variance inter exp√©riences L‚Äôexactitude des pr√©dictions obtenues par les diff√©rents mod√®les est pr√©sent√©e dans la table 2 Les r√©sultats montre que CPT+ continue comme CPT d‚Äôoffrir une exactitude g√©n√©ralement nettement sup√©rieure aux autres mod√®les populaires de la litt√©rature Jeu de donn√©es CPT+ CPT AKOM DG LZ78 PPM TDAG BMS 38 25 37 90 31 26 36 46 33 46 31 06 6 95 SIGN 33 01 32 33 8 63 3 01 4 79 4 25 0 00 MSNBC 61 50 61 64 47 88 55 68 43 64 38 06 31 14 Bible word 27 52 22 05 38 68 24 92 27 39 27 06 11 17 Bible char 73 52 69 14 7 96 0 00 3 02 0 10 0 00 Kosarak 37 64 33 82 20 52 30 82 20 50 23 86 1 06 FIFA 35 94 34 56 25 88 24 78 24 64 22 84 7 14 TAB 2 ‚Äì Les mod√®les de pr√©diction √©valu√©s sur leurs exactitude 6 Conclusion Dans cet article nous avons pr√©sent√© trois strat√©gies pour r√©duire la taille et le temps de pr√©diction de CPT nomm√©es CCF Compression des Cha√Ænes Fr√©quences CBS Compression des Branches Simples et PBA Pr√©duction avec r√©duction du Bruit Am√©lior√©e Les r√©sultats exp√©rimentaux sur 7 jeux de donn√©es r√©els ont montr√© que le mod√®le r√©sultant nomm√© CPT+ est jusqu‚Äô√† 98 fois plus compact que CPT et que cette compression demeure lorsque le nombre de s√©quence augmente En termes de temps d‚Äôex√©cution CPT+ s‚Äôest montr√© jusqu‚Äô√† 4 5 fois plus rapide que CPT Finalement CPT+ s‚Äôest montr√© comme √©tant le mod√®le offrant les pr√© dictions g√©n√©ralement les plus exactes dans une comparaison avec les principaux mod√®les de la litt√©rature CPT All K order Markov DG Lz78 PPM et TDAG Comme travaux futurs nous adapterons CPT+ pour la pr√©diction de s√©quences dans le contexte d‚Äôun flux infini de s√©quences CPT+ de par sa nature incr√©mentale pourrait √™tre adapt√© √† ce probl√®me 69 R√©duction de la complexit√© spatiale temporelle du Compact Prediction Tree R√©f√©rences Begleiter R R El yaniv et G Yona 2004 On prediction using variable order markov models Journal of Artificial Intelligence Research 22 385‚Äì421 Cleary J G et I Witten 1984 Data compression using adaptive coding and partial string matching Communications IEEE Transactions on 32 4 396‚Äì402 Deshpande M et G Karypis 2004 Selective markov models for predicting web page ac cesses ACM Transactions on Internet Technology TOIT 4 2 163‚Äì184 Fournier Viger P T Gueniche et V S Tseng 2012 Using partially ordered sequential rules to generate more accurate sequence prediction In Advanced Data Mining and Applications pp 431‚Äì442 Springer Gopalratnam K et D J Cook 2007 Online sequential prediction via incremental parsing The active lezi algorithm Intelligent Systems IEEE 22 1 52‚Äì58 Gueniche T P Fournier Viger et V S Tseng 2013 Compact prediction tree A lossless model for accurate sequence prediction In Advanced Data Mining and Applications pp 177‚Äì188 Springer Laird P et R Saul 1994 Discrete sequence prediction and its applications Machine lear ning 15 1 43‚Äì68 Padmanabhan V N et J C Mogul 1996 Using predictive prefetching to improve world wide web latency ACM SIGCOMM Computer Communication Review 26 3 22‚Äì36 Pei J J Han B Mortazavi Asl H Pinto Q Chen U Dayal et M C Hsu 2001 Pre fixspan Mining sequential patterns efficiently by prefix projected pattern growth In 2013 IEEE 29th International Conference on Data Engineering ICDE pp 0215‚Äì0215 IEEE Computer Society Pitkow J et P Pirolli 1999 Mining longest repeating subsequence to predict world wide web surfing In Proc USENIX Symp On Internet Technologies and Systems pp 1 Sun R et C L Giles 2001 Sequence learning from recognition and prediction to sequential decision making IEEE Intelligent Systems 16 4 67‚Äì70 Ziv J et A Lempel 1978 Compression of individual sequences via variable rate coding Information Theory IEEE Transactions on 24 5 530‚Äì536 Summary Predicting the next symbol of a sequence of symbols is a task with wide applications The Compact Prediction Tree CPT is a recently proposed prediction model that provide more accurate predictions than several state of the art prediction models In this paper we introduce new strategies to reduce the size of CPT and its prediction time Experimental results on seven datasets shows that the resulting model is up to 98% more compact than CPT and 4 5 times faster and remains on overall much more accurate than state of the art predictions models All K order Markov DG Lz78 PPM and TDAG 70 A Donn√©es Textuelles et S√©quentielles CPT+ R√©duction de la complexit√© temporelle et spatiale du Compact Prediction Tree pour la pr√©diction de s√©quences Ted Gueniche Philippe Fournier Viger